# -*- coding: utf-8 -*-
"""NotBOT_App.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b4zjwQXxYa5JA4Yc7dKTZNdbINw4kF6j
"""

import streamlit as st
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder

# Load your trained model (replace with the actual path to your model)
model = tf.keras.models.load_model('NotBOT_V1.keras')

# Define label encoders for each feature
le_issuetype = LabelEncoder()
le_issuetype.fit(['Analyze', 'Below The Line', 'Build and Test', 'CGI Project', 'Change Request', 'Communicate - Escalate', 'Conduct Meeting', 'Defect', 'Deploy', 'Design', 'Document', 'Documentation', 'Epic', 'Fix', 'Manage Service', 'Portfolio Epic', 'Pre-Condition', 'Prepare Test', 'Report', 'Service Management', 'Service Operation', 'Setup Environment', 'Story', 'Sub Test Execution', 'Sub-Task', 'Support', 'Task', 'Test', 'Test Execution', 'Test Plan', 'Test Set', 'Validate and Execute Test'])

# Define mappings for other categorical features
priority_mapping = {'Critical': 0, 'High': 1, 'Low': 2, 'Medium': 3}
rootcause_mapping = {'Baseline Defect': 0, 'Code': 1, 'Configuration Management': 2, 'Configurations': 3, 'Data': 4, 'Database': 5, 'Design': 6, 'Development - Coding Standards Not Met': 7, 'Development - Inadequate Unit Testing': 8, 'Development - Inappropriate, Inconsistent, or Inefficient Code Design Choice': 9}
severity_mapping = {'Severity 1': 0, 'Severity 2': 1, 'Severity 3': 2, 'Severity 4': 3}
status_mapping = {'Analysis': 0, 'Approved': 1, 'Backlog': 2, 'Closed': 3, 'Executing': 4, 'External Pending': 5, 'In Progress': 6, 'In Review': 7, 'Internal Pending': 8, 'Investigate & Diagnose': 9}
systemenvironment_mapping = {'---Select Browser---': 0, 'Chrome': 1, 'Chrome & Edge': 2, 'Chrome & IE': 3, 'DEV': 4, 'Edge': 5, 'Not Configured': 6, 'Performance': 7, 'Production': 8, 'SIT': 9, 'SIT2': 10, 'Training': 11, 'UAT': 12, 'UAT2': 13}
targetversion_mapping = {'1.0.2': 0, '10.0.10': 1, '10.0.11': 2, '10.0.12': 3, '10.0.13': 4}
testexecutiontype_mapping = {'Automated[Cucumber]': 0, 'Automated[Generic]': 1, 'Manual': 2}
testphase_mapping = {'System': 0, 'System Integration': 1, 'Unit': 2, 'User Acceptance Test': 3}

# Target variable label encoder for 5 bins
le_target = LabelEncoder()
le_target.fit(['Bin1', 'Bin2', 'Bin3', 'Bin4', 'Bin5'])  # Replace with your actual categories

# Streamlit page setup
st.title("NotBOT: Your friendly time manager")

# Feature Inputs
issuetype = st.selectbox('Issuetype', le_issuetype.classes_)
priority = st.selectbox('Priority', ['Critical', 'High', 'Low', 'Medium'])
rootcause = st.selectbox('Rootcause', rootcause_mapping.keys())
severity = st.selectbox('Severity', severity_mapping.keys())
status = st.selectbox('Status', status_mapping.keys())
storypoints = st.selectbox('Storypoints', [0.0, 0.01, 0.1, 0.2, 0.25, 0.3, 0.5, 1.0, 1.5, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 20.0, 21.0, 24.0, 25.0, 29.0, 30.0, 34.0, 35.0, 40.0, 45.0, 50.0, 55.0, 60.0])
systemenvironment = st.selectbox('System Environment', systemenvironment_mapping.keys())
targetversion = st.selectbox('Target Version', targetversion_mapping.keys())
testexecutiontype = st.selectbox('Test Execution Type', testexecutiontype_mapping.keys())
testphase = st.selectbox('Test Phase', testphase_mapping.keys())

# Button to make prediction
if st.button('Predict Time Spent Category'):
    # Preprocess the input data (perform label encoding on categorical features)
    encoded_input = np.array([
        le_issuetype.transform([issuetype])[0],
        priority_mapping[priority],
        rootcause_mapping[rootcause],
        severity_mapping[severity],
        status_mapping[status],
        storypoints,
        systemenvironment_mapping[systemenvironment],
        targetversion_mapping[targetversion],
        testexecutiontype_mapping[testexecutiontype],
        testphase_mapping[testphase]
    ]).reshape(1, -1)

    # Make prediction using the trained model
    prediction = model.predict(encoded_input)  # Outputs probabilities for each bin

    # Convert prediction to the original category
    predicted_category = le_target.inverse_transform([np.argmax(prediction)])

    # Display the result
    st.write(f"Predicted Time Spent Category: {predicted_category[0]}")

    # Display prediction probabilities for each bin
    probabilities = {category: round(prob, 2) for category, prob in zip(le_target.classes_, prediction[0])}
    st.write("Prediction Probabilities for Each Category:", probabilities)



